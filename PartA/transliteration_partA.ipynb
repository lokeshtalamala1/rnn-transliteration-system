{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7lbaH1BGnHX"
      },
      "outputs": [],
      "source": [
        "# Imports & Setup\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import random\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "\n",
        ".\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from utils import (\n",
        "    load_pairs, prepare_vocab, word2tensor,\n",
        "    EncoderRNN, DecoderRNN,\n",
        "    SOS_token, EOS_token, device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device Config\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "id": "G5SXp_CMMGnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset (Dakshina)\n",
        "# Path to Dakshina dataset (change if needed)\n",
        "data_path = \"../dakshina_dataset_v1.0/hi/lexicons/hi.transliteration.train.tsv\"\n",
        "\n",
        "pairs = []\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        native, latin, _ = line.strip().split(\"\\t\")\n",
        "        pairs.append((latin, native))\n",
        "\n",
        "print(\"Total pairs:\", len(pairs))\n",
        "print(\"Example:\", pairs[0])\n"
      ],
      "metadata": {
        "id": "eh8-cg9EMJxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing & Vocabulary\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Vocab:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.char2index = {\"SOS\": SOS_token, \"EOS\": EOS_token}\n",
        "        self.char2count = {}\n",
        "        self.index2char = {SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
        "        self.n_chars = 2\n",
        "\n",
        "    def add_word(self, word):\n",
        "        for ch in word:\n",
        "            self.add_char(ch)\n",
        "\n",
        "    def add_char(self, ch):\n",
        "        if ch not in self.char2index:\n",
        "            self.char2index[ch] = self.n_chars\n",
        "            self.char2count[ch] = 1\n",
        "            self.index2char[self.n_chars] = ch\n",
        "            self.n_chars += 1\n",
        "        else:\n",
        "            self.char2count[ch] += 1\n",
        "\n",
        "def prepare_vocab(pairs):\n",
        "    src_vocab = Vocab(\"Latin\")\n",
        "    tgt_vocab = Vocab(\"Native\")\n",
        "    for src, tgt in pairs:\n",
        "        src_vocab.add_word(src)\n",
        "        tgt_vocab.add_word(tgt)\n",
        "    return src_vocab, tgt_vocab\n",
        "\n",
        "src_vocab, tgt_vocab = prepare_vocab(pairs)\n",
        "print(\"Latin vocab size:\", src_vocab.n_chars)\n",
        "print(\"Native vocab size:\", tgt_vocab.n_chars)\n"
      ],
      "metadata": {
        "id": "Q2EpgY7QMNhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper: Tensor Conversion\n",
        "def word2tensor(vocab, word):\n",
        "    indexes = [vocab.char2index[ch] for ch in word] + [EOS_token]\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n"
      ],
      "metadata": {
        "id": "_D3nOoHlMQo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder Model\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, cell_type=\"LSTM\"):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        if cell_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(hidden_size, hidden_size)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(hidden_size, hidden_size)\n",
        "        else:\n",
        "            self.rnn = nn.RNN(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ],
      "metadata": {
        "id": "gFoYxAFvMXDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder Model\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, cell_type=\"LSTM\"):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        if cell_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(hidden_size, hidden_size)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(hidden_size, hidden_size)\n",
        "        else:\n",
        "            self.rnn = nn.RNN(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n"
      ],
      "metadata": {
        "id": "sAhQvP_HMZr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Step\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train_step(input_tensor, target_tensor, encoder, decoder,\n",
        "               encoder_optimizer, decoder_optimizer, criterion, max_length=30):\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        _, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "    else:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n"
      ],
      "metadata": {
        "id": "NA15LdCqMeg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "def train_iters(pairs, encoder, decoder, n_iters=1000, learning_rate=0.01, print_every=100):\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for it in range(1, n_iters+1):\n",
        "        src, tgt = random.choice(pairs)\n",
        "        input_tensor = word2tensor(src_vocab, src)\n",
        "        target_tensor = word2tensor(tgt_vocab, tgt)\n",
        "\n",
        "        loss = train_step(input_tensor, target_tensor, encoder, decoder,\n",
        "                          encoder_optimizer, decoder_optimizer, criterion)\n",
        "\n",
        "        if it % print_every == 0:\n",
        "            print(f\"Iter {it}, Loss {loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "irVpxoY9MjNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "def evaluate(encoder, decoder, word, max_length=30):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = word2tensor(src_vocab, word)\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "        for ei in range(input_tensor.size(0)):\n",
        "            _, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_chars = []\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                break\n",
        "            else:\n",
        "                decoded_chars.append(tgt_vocab.index2char[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return ''.join(decoded_chars)\n"
      ],
      "metadata": {
        "id": "z3E8ChOoMnyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Training + Test\n",
        "hidden_size = 256\n",
        "encoder = EncoderRNN(src_vocab.n_chars, hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, tgt_vocab.n_chars).to(device)\n",
        "\n",
        "train_iters(pairs, encoder, decoder, n_iters=2000, print_every=200)\n",
        "\n",
        "# Test some predictions\n",
        "for word, tgt in random.sample(pairs, 5):\n",
        "    pred = evaluate(encoder, decoder, word)\n",
        "    print(f\"{word} -> {pred} (target: {tgt})\")\n"
      ],
      "metadata": {
        "id": "szPdVsrAMs60"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}