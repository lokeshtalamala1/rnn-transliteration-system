{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9GWL66vGtnv"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "from utils import (\n",
        "    load_pairs, prepare_vocab, word2tensor,\n",
        "    SOS_token, EOS_token, device\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "data_path = \"../dakshina_dataset_v1.0/hi/lexicons/hi.transliteration.train.tsv\"\n",
        "\n",
        "pairs = load_pairs(data_path)\n",
        "src_vocab, tgt_vocab = prepare_vocab(pairs)\n",
        "\n",
        "print(\"Latin vocab size:\", src_vocab.n_chars)\n",
        "print(\"Native vocab size:\", tgt_vocab.n_chars)\n",
        "print(\"Example pair:\", pairs[0])\n"
      ],
      "metadata": {
        "id": "hDRZ4TlIQal0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention Module\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.v = nn.Parameter(torch.rand(hidden_size))\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        # hidden: (1, batch, hidden_size)\n",
        "        # encoder_outputs: (seq_len, hidden_size)\n",
        "        seq_len = encoder_outputs.size(0)\n",
        "        hidden = hidden.squeeze(0).repeat(seq_len, 1)  # (seq_len, hidden_size)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), 1)))\n",
        "        energy = energy @ self.v  # (seq_len,)\n",
        "        return F.softmax(energy, dim=0).unsqueeze(0)  # (1, seq_len)\n"
      ],
      "metadata": {
        "id": "g6AaT6KdQeT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, cell_type=\"LSTM\"):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.rnn = nn.LSTM(hidden_size, hidden_size) if cell_type == \"LSTM\" else nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n"
      ],
      "metadata": {
        "id": "QUGPn6rPQi_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention Decoder\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=30, cell_type=\"LSTM\"):\n",
        "        super().__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "        if cell_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(hidden_size * 2, hidden_size)\n",
        "        else:\n",
        "            self.rnn = nn.GRU(hidden_size * 2, hidden_size)\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = self.attention(hidden[0] if isinstance(hidden, tuple) else hidden,\n",
        "                                      encoder_outputs.squeeze(1))\n",
        "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))  # (1,1,hidden)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, context), 2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "        output = self.out(output[0])\n",
        "        return F.log_softmax(output, dim=1), hidden, attn_weights\n"
      ],
      "metadata": {
        "id": "nZ0s_2DxQmO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Step with Attention\n",
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def train_step(input_tensor, target_tensor, encoder, decoder,\n",
        "               encoder_optimizer, decoder_optimizer, criterion,\n",
        "               max_length=30):\n",
        "    encoder_hidden = encoder.init_hidden()\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, 1, encoder.hidden_size, device=device)\n",
        "\n",
        "    # Encoder forward\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "    decoder_hidden = encoder_hidden\n",
        "    loss = 0\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "    if use_teacher_forcing:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]\n",
        "    else:\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "    return loss.item() / target_length\n"
      ],
      "metadata": {
        "id": "rJy2LJMFQqmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "def train_iters(pairs, encoder, decoder, src_vocab, tgt_vocab,\n",
        "                n_iters=1000, learning_rate=0.01, print_every=100):\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for it in range(1, n_iters + 1):\n",
        "        src, tgt = random.choice(pairs)\n",
        "        input_tensor = word2tensor(src_vocab, src)\n",
        "        target_tensor = word2tensor(tgt_vocab, tgt)\n",
        "\n",
        "        loss = train_step(input_tensor, target_tensor, encoder, decoder,\n",
        "                          encoder_optimizer, decoder_optimizer, criterion)\n",
        "\n",
        "        if it % print_every == 0:\n",
        "            print(f\"Iter {it}, Loss {loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "D5TAxwmAQtZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation with Attention\n",
        "def evaluate(encoder, decoder, word, src_vocab, tgt_vocab, max_length=30):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = word2tensor(src_vocab, word)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, 1, encoder.hidden_size, device=device)\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "            encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_chars, attentions = [], torch.zeros(max_length, max_length)\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, attn_weights = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "            attentions[di, :attn_weights.size(-1)] = attn_weights.squeeze(0)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                break\n",
        "            decoded_chars.append(tgt_vocab.index2char[topi.item()])\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return ''.join(decoded_chars), attentions[:len(decoded_chars), :input_length]\n"
      ],
      "metadata": {
        "id": "cS9cZADhQwJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention Heatmap Utility\n",
        "def show_attention(input_word, output_word, attentions):\n",
        "    fig = plt.figure(figsize=(6,6))\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='viridis')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    ax.set_xticklabels([''] + list(input_word) + ['EOS'], rotation=90)\n",
        "    ax.set_yticklabels([''] + list(output_word))\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "7CmnmrysQzOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Training + Test Predictions\n",
        "hidden_size = 256\n",
        "encoder = EncoderRNN(src_vocab.n_chars, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, tgt_vocab.n_chars, dropout_p=0.1).to(device)\n",
        "\n",
        "train_iters(pairs, encoder, decoder, src_vocab, tgt_vocab, n_iters=2000, print_every=200)\n",
        "\n",
        "# Show some predictions with attention maps\n",
        "for word, tgt in random.sample(pairs, 3):\n",
        "    pred, attn = evaluate(encoder, decoder, word, src_vocab, tgt_vocab)\n",
        "    print(f\"{word} -> {pred} (target: {tgt})\")\n",
        "    show_attention(word, pred, attn)\n"
      ],
      "metadata": {
        "id": "IEfTOLLQQ2o4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}